# æŠ€è¡“ãƒ¬ãƒãƒ¼ãƒˆ - Rinna-3.6B LoRAãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°

## ğŸ”§ ä½¿ç”¨æŠ€è¡“

### åŸºç›¤æŠ€è¡“
- **Python 3.x**: ãƒ¡ã‚¤ãƒ³é–‹ç™ºè¨€èª
- **PyTorch**: æ·±å±¤å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
- **Transformers (Hugging Face)**: äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«æ“ä½œ
- **PEFT (Parameter-Efficient Fine-Tuning)**: LoRAå®Ÿè£…
- **BitsAndBytes**: ãƒ¢ãƒ‡ãƒ«é‡å­åŒ–
- **Datasets (Hugging Face)**: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå‡¦ç†

### ãƒ¢ãƒ‡ãƒ«ãƒ»ãƒ‡ãƒ¼ã‚¿
- **ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«**: rinna/japanese-gpt-neox-3.6b (3.6B parameters)
- **ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ**: kunishou/databricks-dolly-15k-ja (15,015ä»¶)
- **ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼**: T5Tokenizer (use_fast=False)

### ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æŠ€è¡“
- **LoRA (Low-Rank Adaptation)**: åŠ¹ç‡çš„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´
- **é‡å­åŒ–**: 4bit/8bitç²¾åº¦ã§ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–
- **å‹¾é…è“„ç©**: å®ŸåŠ¹ãƒãƒƒãƒã‚µã‚¤ã‚ºæ‹¡å¤§
- **FP16**: åŠç²¾åº¦æµ®å‹•å°æ•°ç‚¹æ¼”ç®—

## âš™ï¸ ä½œæˆæ¡ä»¶

### ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ç’°å¢ƒ
```
GPU: NVIDIA A100-SXM4-40GB (39.6GB VRAM)
CPU: Intel/AMD å¤šã‚³ã‚¢
RAM: ååˆ†ãªã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒ¢ãƒª
OS: Linux (Ubuntu/CentOSç­‰)
```

### ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ç’°å¢ƒ
```
CUDA: 11.8+
Python: 3.8+
PyTorch: 2.0+
Transformers: 4.30+
PEFT: 0.4+
```

### LoRAãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
```
r (rank): 8
alpha: 32
dropout: 0.1
target_modules: ["query_key_value"]
bias: "none"
task_type: "CAUSAL_LM"
```

### å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

#### å¾“æ¥ç‰ˆ
```
batch_size: 4
gradient_accumulation_steps: 4
learning_rate: 1e-4
epochs: 1
quantization: 8bit
warmup_steps: 100
```

#### A100æœ€é©åŒ–ç‰ˆ
```
batch_size: 16
gradient_accumulation_steps: 2
learning_rate: 2e-4
epochs: 1
quantization: 4bit
warmup_steps: 100
dataloader_num_workers: 4
```

### ãƒ‡ãƒ¼ã‚¿å‡¦ç†
```
max_length: 512 tokens
padding: True
truncation: True
preprocessing: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆé©ç”¨
validation_split: ãªã—ï¼ˆå…¨ãƒ‡ãƒ¼ã‚¿å­¦ç¿’ï¼‰
```

## ğŸ“Š æ€§èƒ½æŒ‡æ¨™

### å­¦ç¿’çµæœ
```
ç·ã‚¹ãƒ†ãƒƒãƒ—æ•°: 470 (æœ€é©åŒ–ç‰ˆ)
å­¦ç¿’æ™‚é–“: 9åˆ†44ç§’ (584.28ç§’)
æœ€çµ‚æå¤±: 1.9839
å¹³å‡æå¤±: 2.039
å‡¦ç†é€Ÿåº¦: 25.7 samples/sec
```

### ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡
```
VRAMä½¿ç”¨é‡: 18.96GB / 39.6GB (47.8%)
GPUä½¿ç”¨ç‡: 100%
æ¶ˆè²»é›»åŠ›: 369W (æœ€å¤§æ€§èƒ½)
å­¦ç¿’å¯èƒ½ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: 3.2M (0.09%)
```

### ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º
```
LoRAã‚¢ãƒ€ãƒ—ã‚¿: 12.9MB
ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«: 7.2GB (é‡å­åŒ–æ¸ˆã¿)
ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ: ~100MB
```

## ğŸ› ï¸ å®Ÿè£…ç‰¹å¾´

### æœ€é©åŒ–æŠ€è¡“
1. **4bité‡å­åŒ–**: ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡å‰Šæ¸›
2. **ãƒãƒƒãƒã‚µã‚¤ã‚ºæœ€å¤§åŒ–**: A100ã®èƒ½åŠ›æ´»ç”¨
3. **ä¸¦åˆ—ãƒ‡ãƒ¼ã‚¿å‡¦ç†**: 4ãƒ—ãƒ­ã‚»ã‚¹ä¸¦åˆ—
4. **å‹¾é…è“„ç©**: å®ŸåŠ¹ãƒãƒƒãƒã‚µã‚¤ã‚º32
5. **fp16ç²¾åº¦**: è¨ˆç®—é«˜é€ŸåŒ–

### ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
```
### æŒ‡ç¤º:
{instruction}

### å…¥åŠ›:
{input}

### å›ç­”:
{response}
```

### æ¨è«–æœ€é©åŒ–
```
temperature: 0.7
top_p: 0.75
top_k: 40
no_repeat_ngram_size: 2
max_new_tokens: 256
```

## ğŸ“ æˆæœç‰©æ§‹æˆ

### å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
- `rinna_3_6b_lora_training.py`: è¨˜äº‹å¿ å®Ÿç‰ˆ
- `rinna_3_6b_lora_training_optimized.py`: A100æœ€é©åŒ–ç‰ˆ
- `rinna_3_6b_inference.py`: ãƒ†ã‚¹ãƒˆä»˜ãæ¨è«–
- `rinna_3_6b_inference_interactive.py`: å¯¾è©±å°‚ç”¨æ¨è«–

### å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
- `lora-rinna-3.6b-optimized/`: æœ€é©åŒ–ç‰ˆLoRAãƒ¢ãƒ‡ãƒ«
- `lora-rinna-3.6b-results-optimized/`: å­¦ç¿’ãƒ­ã‚°ãƒ»ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ

### è¨­å®šãƒ»ç’°å¢ƒ
- `requirements.txt`: Pythonä¾å­˜é–¢ä¿‚
- `setup_environment.py`: ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
- `.gitignore`: Gité™¤å¤–è¨­å®š

## ğŸ¯ æŠ€è¡“çš„æˆæœ

### åŠ¹ç‡åŒ–é”æˆ
- **å­¦ç¿’ã‚¹ãƒ†ãƒƒãƒ—**: 3,754 â†’ 470 (87%å‰Šæ¸›)
- **ãƒãƒƒãƒã‚µã‚¤ã‚º**: 4 â†’ 16 (4å€å¢—åŠ )
- **VRAMæ´»ç”¨**: 9GB â†’ 19GB (2å€å‘ä¸Š)
- **GPUä½¿ç”¨ç‡**: 95% â†’ 100% (æœ€å¤§æ´»ç”¨)

### å“è³ªç¶­æŒ
- **æå¤±æ”¹å–„**: 2.737 â†’ 1.984
- **åæŸå®‰å®š**: å‹¾é…ãƒãƒ«ãƒ 0.4-0.6
- **å‡ºåŠ›å“è³ª**: è‡ªç„¶ãªæ—¥æœ¬èªç”Ÿæˆ
- **å¿œç­”é€Ÿåº¦**: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¯¾è©±å¯èƒ½

## ğŸ” å‚è€ƒæ–‡çŒ®

- **å…ƒè¨˜äº‹**: [Google Colab ã§ Rinna-3.6B ã®LoRAãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è©¦ã™](https://note.com/npaka/n/nc387b639e50e)
- **LoRAè«–æ–‡**: "LoRA: Low-Rank Adaptation of Large Language Models"
- **Rinnaå…¬å¼**: [rinna/japanese-gpt-neox-3.6b](https://huggingface.co/rinna/japanese-gpt-neox-3.6b)
- **ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ**: [kunishou/databricks-dolly-15k-ja](https://huggingface.co/datasets/kunishou/databricks-dolly-15k-ja) 